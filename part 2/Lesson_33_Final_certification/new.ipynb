{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14492f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve, f1_score\n",
    "from category_encoders import TargetEncoder\n",
    "from category_encoders.basen import BaseNEncoder\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "\n",
    "def calculate_metrics_and_plot_roc_comparison(\n",
    "    model,\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    best_threshold: float\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Рассчитывает метрики классификации и строит ROC-кривые для train и test выборок на одном графике.\n",
    "\n",
    "    Параметры:\n",
    "    ----------\n",
    "    model :\n",
    "        Обученная модель, реализующая метод predict_proba.\n",
    "\n",
    "    X_train : np.ndarray\n",
    "        Признаки обучающей выборки.\n",
    "\n",
    "    y_train : np.ndarray\n",
    "        Истинные метки классов обучающей выборки.\n",
    "\n",
    "    X_test : np.ndarray\n",
    "        Признаки тестовой выборки.\n",
    "\n",
    "    y_test : np.ndarray\n",
    "        Истинные метки классов тестовой выборки.\n",
    "\n",
    "    best_threshold: float\n",
    "      Порог для бинарного прогноза.\n",
    "\n",
    "    Возвращает:\n",
    "    -----------\n",
    "    metrics : dict\n",
    "        Словарь с метриками для обеих выборок.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for X, y, sample_type in [(X_train, y_train, \"train\"), (X_test, y_test, \"test\")]:\n",
    "        # Предсказание вероятностей\n",
    "        y_proba = model.predict_proba(X)[:, 1]\n",
    "\n",
    "        # Прогноз с учетом порога\n",
    "        y_pred = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "        # Вычисление метрик\n",
    "        precision = precision_score(y, y_pred)\n",
    "        recall = recall_score(y, y_pred)\n",
    "        roc_auc = roc_auc_score(y, y_proba)\n",
    "        fpr, tpr, _ = roc_curve(y, y_proba)\n",
    "\n",
    "        # Сохранение результатов\n",
    "        results[sample_type] = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'roc_auc': roc_auc,\n",
    "            'fpr': fpr,\n",
    "            'tpr': tpr,\n",
    "            'threshold': best_threshold\n",
    "        }\n",
    "\n",
    "    # Построение ROC-кривых на одном графике\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    colors = {'train': 'blue', 'test': 'red'}\n",
    "    for sample_type in ['train', 'test']:\n",
    "        plt.plot(\n",
    "            results[sample_type]['fpr'],\n",
    "            results[sample_type]['tpr'],\n",
    "            color=colors[sample_type],\n",
    "            lw=2,\n",
    "            label=f'{sample_type.capitalize()} (AUC = {results[sample_type][\"roc_auc\"]:.2f})'\n",
    "        )\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title(f'ROC Curves Comparison ({type(model).__name__})', fontsize=14)\n",
    "    plt.legend(loc=\"lower right\", fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    return results\n",
    "# import category_encoders as ce\n",
    "\n",
    "\n",
    "def load_dataset(from_kaggle: bool = False) -> pd.DataFrame:\n",
    "  '''\n",
    "  Функция скачивает данные с сайта kaggle, если установлен from_kaggle=True,\n",
    "  инчае архив считывается по ссылке с гугл диска (такой способ удобен тем, у кого нет доступа к kaggle)\n",
    "  params:\n",
    "      - from_kaggle - индикатор откуда скачивать данные (True - c сайта kaggle, False -  c google диска)\n",
    "  return:\n",
    "      - pd.DataFrame\n",
    "\n",
    "  '''\n",
    "  '''\n",
    "  if from_kaggle:\n",
    "    # запросит разрешение к гугл диску, необходимо дать это разрешение\n",
    "    drive.mount('/content/drive')\n",
    "    # установим kaggle\n",
    "    !pip install kaggle -q\n",
    "    !mkdir ~/.kaggle\n",
    "    # копируем kaggle.json (предварительно, необходимо сгенерить токен на\n",
    "    # сайте kaggle и сохранить к себе на гугл диск) в папку ~/.kaggle/\n",
    "    !cp \"/content/drive/MyDrive/Colab Notebooks/config/kaggle.json\" ~/.kaggle/\n",
    "    !kaggle competitions download -c playground-series-s5e7\n",
    "    # !kaggle competitions download -c playground-series-s5e3\n",
    "  else:\n",
    "    !gdown 1-730JF1IWA5e_ejuXWLmkkzHFvudisdp\n",
    "  '''\n",
    "  # распаковка архива\n",
    "  zip_ref = zipfile.ZipFile('playground-series-s5e7.zip', 'r')\n",
    "  zip_ref.extractall()\n",
    "  zip_ref.close()\n",
    "  df_train = pd.read_csv('train.csv')\n",
    "  df_test = pd.read_csv('test.csv')\n",
    "  df_sample_submission = pd.read_csv('sample_submission.csv')\n",
    "  return df_train, df_test, df_sample_submission\n",
    "\n",
    "\n",
    "df_train, df_test, df_sample_submission = load_dataset(from_kaggle=False)\n",
    "df_train\n",
    "\n",
    "df_train.columns = (col.lower().replace(\"(\", \"_\").replace(\n",
    "    \")\", \"\").replace(\" \", \"_\") for col in df_train.columns)\n",
    "df_train.columns = (col.lower().replace(\"(\", \"_\").replace(\n",
    "    \")\", \"\").replace(\" \", \"_\") for col in df_train.columns)\n",
    "df_test.columns = (col.lower().replace(\"(\", \"_\").replace(\n",
    "    \")\", \"\").replace(\" \", \"_\") for col in df_test.columns)\n",
    "df_train['personality'].unique()\n",
    "\n",
    "dict_personality = {'Extrovert': 0, 'Introvert': 1}\n",
    "df_train['int_personality'] = df_train['personality'].map(dict_personality)\n",
    "df_train.shape\n",
    "\n",
    "df_train.describe(include='all').T\n",
    "df_train['time_spent_alone'].value_counts(normalize=True, dropna=False)\n",
    "df_train['drained_after_socializing'].value_counts(\n",
    "    normalize=True, dropna=False)\n",
    "df_train['stage_fear'].value_counts(normalize=True, dropna=False)\n",
    "df_train['drained_after_socializing'].value_counts(\n",
    "    normalize=True, dropna=False)\n",
    "df_train['social_event_attendance'].value_counts(normalize=True, dropna=False)\n",
    "df_train['friends_circle_size'].isna().mean()\n",
    "df_train.groupby('personality')['friends_circle_size'].mean()\n",
    "df_train['post_frequency'].isna().mean()\n",
    "df_train[pd.isna(df_train['post_frequency'])].isna().sum()\n",
    "df_train.isna().sum()\n",
    "msno.matrix(df_train)\n",
    "id_features = ['id', ]\n",
    "target = 'int_personality'\n",
    "exclude_features = ['personality',]\n",
    "\n",
    "num_features = [col for col in df_train.select_dtypes(include='number').columns\n",
    "                if col not in id_features + [target, ] + exclude_features]\n",
    "\n",
    "cat_features = [col for col in df_train.select_dtypes(exclude='number').columns\n",
    "                if col not in id_features + [target, ] + exclude_features]\n",
    "num_features\n",
    "df_train.info()\n",
    "df_train.isna().sum()[df_train.isna().sum() > 0]\n",
    "df_train\n",
    "sns.barplot(df_train[target].value_counts(normalize=True))\n",
    "label_encoder = LabelEncoder()\n",
    "df_encoded = df_train.copy()\n",
    "df_encoded['stage_fear'] = label_encoder.fit_transform(\n",
    "    df_encoded['stage_fear'])\n",
    "df_encoded['drained_after_socializing'] = label_encoder.fit_transform(\n",
    "    df_encoded['drained_after_socializing'])\n",
    "df_encoded['personality'] = label_encoder.fit_transform(\n",
    "    df_encoded['personality'])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df_encoded.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Корреляционная матрица')\n",
    "plt.show()\n",
    "df_train.head()\n",
    "df_train[num_features + cat_features].loc[75, :]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[num_features + cat_features],\n",
    "                                                    df_train[target],\n",
    "                                                    stratify=df_train[target],\n",
    "                                                    train_size=0.75,\n",
    "                                                    random_state=12345)\n",
    "X_test.head()\n",
    "X_test.shape, X_train.shape\n",
    "# SimpleImputer + OHE\n",
    "cat_pipe = Pipeline(\n",
    "    [\n",
    "\n",
    "        (\n",
    "            'enc',\n",
    "            TargetEncoder(cols=cat_features)\n",
    "\n",
    "        ),\n",
    "        (\n",
    "            'imputer',\n",
    "            SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "        ),\n",
    "\n",
    "    ]\n",
    ")\n",
    "# TODO разделить pipeline: некоторые переменные -0 , некоторые среднее (или модель)\n",
    "# SimpleImputer + StandardScaler\n",
    "num_pipe = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            'scaler',\n",
    "            StandardScaler()\n",
    "        ),\n",
    "        (\n",
    "            'imputer',\n",
    "            SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        ),\n",
    "\n",
    "    ]\n",
    ")\n",
    "data_preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('cat', cat_pipe, cat_features),\n",
    "        ('num', num_pipe, num_features),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "type(data_preprocessor.fit_transform(X_train, y_train))\n",
    "data_preprocessor.get_feature_names_out()\n",
    "X_train_p = pd.DataFrame(\n",
    "    data_preprocessor.fit_transform(X_train, y_train),\n",
    "    columns=data_preprocessor.get_feature_names_out()\n",
    ")\n",
    "\n",
    "X_test_p = pd.DataFrame(\n",
    "    data_preprocessor.transform(X_test),\n",
    "    columns=data_preprocessor.get_feature_names_out()\n",
    ")\n",
    "X_train_p.head()\n",
    "X_test_p.head()\n",
    "model_log_reg = LogisticRegression()\n",
    "model_log_reg.fit(X_train_p, y_train)\n",
    "y_pred_test = model_log_reg.predict_proba(X_test_p)\n",
    "y_pred_train = model_log_reg.predict_proba(X_train_p)\n",
    "X_train_p.columns\n",
    "model_log_reg.coef_[0]\n",
    "feature_imp = pd.DataFrame(\n",
    "    {'feature': list(X_train_p.columns), 'coef': model_log_reg.coef_[0]})\n",
    "feature_imp.sort_values('coef', ascending=False)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(feature_imp.sort_values(\n",
    "    'coef', ascending=False), y='feature', x='coef')\n",
    "res = calculate_metrics_and_plot_roc_comparison(\n",
    "    model_log_reg,\n",
    "    X_train_p,\n",
    "    y_train,\n",
    "    X_test_p,\n",
    "    y_test,\n",
    "    0.5)\n",
    "params = {\n",
    "    'criterion': ['gini',],\n",
    "    'max_depth': [5, 10, 15,],  # range(3, 15, 3)\n",
    "    'min_samples_leaf': [10, 15, 20],\n",
    "    'ccp_alpha': np.arange(0.1, 2, 0.5)\n",
    "}\n",
    "tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "# Создаем объект GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=tree_classifier,\n",
    "                           param_grid=params, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_p, y_train)\n",
    "grid_search.best_params_\n",
    "\n",
    "best_tree = grid_search.best_estimator_\n",
    "\n",
    "calculate_metrics_and_plot_roc_comparison(\n",
    "    model_log_reg,\n",
    "    X_train_p,\n",
    "    y_train,\n",
    "    X_test_p,\n",
    "    y_test,\n",
    "    0.5)\n",
    "\n",
    "\n",
    "pred_train = best_tree.predict_proba(X_train_p)\n",
    "pred_test = best_tree.predict_proba(X_test_p)\n",
    "\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\"feature\": X_train_p.columns, \"importance\": best_tree.feature_importances_}\n",
    ").sort_values(by=\"importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# второй способ отрисовать деревья с помощью plot_tree\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_tree(best_tree, feature_names=X_train_p.columns,\n",
    "          filled=True, rounded=True,  fontsize=10)\n",
    "plt.show()\n",
    "plt.savefig('tree.png')\n",
    "\n",
    "\n",
    "# итоговый пайплайн: подготовка данных и модель RandomForestClassifier\n",
    "rf_cl = Pipeline(\n",
    "    [\n",
    "        ('preprocessor', data_preprocessor),\n",
    "        ('rf_models', RandomForestClassifier(random_state=47))\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "rf_cl.fit(X_train, y_train)\n",
    "\n",
    "pred_train = rf_cl.predict_proba(X_train)\n",
    "\n",
    "pred_test = rf_cl.predict_proba(X_test)\n",
    "\n",
    "rf_cl.steps\n",
    "param_grid = {\n",
    "    'rf_models__n_estimators': [100, 300],  # Количество деревьев в лесу\n",
    "    # Функция для измерения качества разделения: индекс Джини или энтропия\n",
    "    'rf_models__criterion': ['gini', ],\n",
    "    # Максимальная глубина дерева: ограничение глубины для избежания переобучения\n",
    "    'rf_models__max_depth': [5, 7, 10],\n",
    "    # Минимальное количество выборок, необходимых для разделения внутреннего узла\n",
    "    'rf_models__min_samples_split': [5, 10],\n",
    "    # Минимальное количество выборок, необходимых для узла листа\n",
    "    'rf_models__min_samples_leaf': [7, 10],\n",
    "    # Количество признаков для поиска наилучшего разделения\n",
    "    'rf_models__max_features': ['log2'],\n",
    "    # 'sqrt' - корень из общего кол-ва признаков, 'log2' - логарифм по основанию 2 от общего кол-ва признаков, None - все признаки\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    rf_cl, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2)\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "# Получаем лучшее значение параметров, найденных в процессе кросс-валидации\n",
    "print(\"Лучшие параметры:\", grid_search.best_params_)\n",
    "\n",
    "pred_train = grid_search.best_estimator_.predict_proba(X_train)\n",
    "\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "pred_test = best_rf_model.predict_proba(X_test)\n",
    "res_rf = calculate_metrics_and_plot_roc_comparison(\n",
    "    best_rf_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    0.5)\n",
    "\n",
    "best_rf_model.steps[1][1]\n",
    "\n",
    "%%time\n",
    "explainer_tree = shap.Explainer(best_rf_model.steps[1][1].predict, X_test_p)\n",
    "shap_values_tree = explainer_tree(X_test_p)\n",
    "\n",
    "i = 1\n",
    "shap.plots.waterfall(shap_values_tree[i], max_display=14)\n",
    "\n",
    "shap.plots.beeswarm(shap_values_tree)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Сохранение пайплайна в файл\n",
    "with open('pipeline_best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_rf_model, f)\n",
    "\n",
    "print(\"Pipeline сохранен в файл 'pipeline_best_model.pkl'.\")\n",
    "\n",
    "\n",
    "# Загрузка пайплайна из файла\n",
    "with open('pipeline_best_model.pkl', 'rb') as f:\n",
    "    loaded_pipeline = pickle.load(f)\n",
    "\n",
    "print(\"Pipeline загружен.\")\n",
    "\n",
    "loaded_pipeline.steps[1][1]\n",
    "# .get_feature_names_out()\n",
    "df_test['pred'] = loaded_pipeline.predict(df_test)\n",
    "\n",
    "#dict_personality = {'Extrovert':0, 'Introvert':1}\n",
    "dict_personality_rev = {0:'Extrovert', 1:'Introvert'}\n",
    "\n",
    "df_test['Personality'] = df_test['pred'].map(dict_personality_rev)\n",
    "\n",
    "\n",
    "df_test[['id', 'Personality']].to_csv('submission_.csv', index=False)\n",
    "\n",
    "!kaggle competitions submit -c playground-series-s5e7 -f submission.csv -m \"1 commit\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
