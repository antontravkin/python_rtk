{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb4ed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b45f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# --- –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---\n",
    "with zipfile.ZipFile('playground-series-s5e7.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "for df in [df_train, df_test]:\n",
    "    df['alone_ratio'] = df['Time_spent_Alone'] / (\n",
    "        df['Time_spent_Alone'] + df['Social_event_attendance'] + df['Going_outside'] + 1)\n",
    "    df['social_ratio'] = df['Social_event_attendance'] / \\\n",
    "        (df['Going_outside'] + 1)\n",
    "    df['is_high_poster'] = (df['Post_frequency'] > 5).astype(int)\n",
    "\n",
    "# --- –ö–æ–¥–∏—Ä–æ–≤–∫–∞ —Ç–∞—Ä–≥–µ—Ç–∞ ---\n",
    "target = 'Personality'\n",
    "label_encoder = LabelEncoder()\n",
    "df_train['target'] = label_encoder.fit_transform(df_train[target])\n",
    "\n",
    "# --- –ü—Ä–∏–∑–Ω–∞–∫–∏ ---\n",
    "num_features = ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside',\n",
    "                'Friends_circle_size', 'Post_frequency', 'alone_ratio', 'social_ratio']\n",
    "cat_features = ['Stage_fear', 'Drained_after_socializing', 'is_high_poster']\n",
    "\n",
    "X = df_train[num_features + cat_features]\n",
    "y = df_train['target']\n",
    "X_test = df_test[num_features + cat_features]\n",
    "\n",
    "# --- –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ ---\n",
    "cat_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('target_encoder', TargetEncoder())\n",
    "])\n",
    "num_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipe, num_features),\n",
    "    ('cat', cat_pipe, cat_features)\n",
    "])\n",
    "\n",
    "# --- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ Optuna ---\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'random_state': 42,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0, 5),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0, 5),\n",
    "    }\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_idx, valid_idx in skf.split(X, y):\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_valid, y_valid = X.iloc[valid_idx], y.iloc[valid_idx]\n",
    "\n",
    "        X_train_prep = preprocessor.fit_transform(X_train, y_train)\n",
    "        X_valid_prep = preprocessor.transform(X_valid)\n",
    "\n",
    "        train_data = lgb.Dataset(X_train_prep, label=y_train)\n",
    "        valid_data = lgb.Dataset(X_valid_prep, label=y_valid)\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets=[valid_data],\n",
    "            num_boost_round=1000,\n",
    "            callbacks=[lgb.early_stopping(\n",
    "                stopping_rounds=50), lgb.log_evaluation(100)]\n",
    "        )\n",
    "\n",
    "        preds = (model.predict(X_valid_prep,\n",
    "                 num_iteration=model.best_iteration) > 0.5).astype(int)\n",
    "        f1 = f1_score(y_valid, preds)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "\n",
    "print(\"üöÄ –ó–∞–ø—É—Å–∫ Optuna –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "print(f\"‚úÖ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {study.best_params}\")\n",
    "print(f\"‚úÖ –õ—É—á—à–∏–π F1 (CV): {study.best_value:.4f}\")\n",
    "\n",
    "# --- –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–æ–±—Ä–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ ---\n",
    "params = study.best_params\n",
    "params.update({\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 42\n",
    "})\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "probas = np.zeros(len(X_test))\n",
    "thresholds = np.linspace(0.3, 0.7, 50)\n",
    "best_thresholds = []\n",
    "val_f1_scores = []\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_valid, y_valid = X.iloc[valid_idx], y.iloc[valid_idx]\n",
    "\n",
    "    X_train_prep = preprocessor.fit_transform(X_train, y_train)\n",
    "    X_valid_prep = preprocessor.transform(X_valid)\n",
    "    X_test_prep = preprocessor.transform(X_test)\n",
    "\n",
    "    train_data = lgb.Dataset(X_train_prep, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid_prep, label=y_valid)\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[valid_data],\n",
    "        num_boost_round=1000,\n",
    "        callbacks=[lgb.early_stopping(50)]\n",
    "    )\n",
    "\n",
    "    val_pred_proba = model.predict(\n",
    "        X_valid_prep, num_iteration=model.best_iteration)\n",
    "\n",
    "    best_f1, best_thr = 0, 0.5\n",
    "    for thr in thresholds:\n",
    "        preds = (val_pred_proba > thr).astype(int)\n",
    "        f1 = f1_score(y_valid, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thr = thr\n",
    "\n",
    "    print(f\"  –õ—É—á—à–∏–π –ø–æ—Ä–æ–≥: {best_thr:.3f}, F1 = {best_f1:.4f}\")\n",
    "\n",
    "    best_thresholds.append(best_thr)\n",
    "    val_f1_scores.append(best_f1)\n",
    "\n",
    "    probas += model.predict(X_test_prep,\n",
    "                            num_iteration=model.best_iteration) / skf.n_splits\n",
    "\n",
    "final_thr = np.mean(best_thresholds)\n",
    "print(f\"\\nüìà –°—Ä–µ–¥–Ω–∏–π F1: {np.mean(val_f1_scores):.4f}\")\n",
    "print(f\"üìå –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥: {final_thr:.3f}\")\n",
    "\n",
    "# --- –§–∏–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ---\n",
    "preds_final = (probas > final_thr).astype(int)\n",
    "df_test['Personality'] = label_encoder.inverse_transform(preds_final)\n",
    "df_test[['id', 'Personality']].to_csv('submission.csv', index=False)\n",
    "print(\"‚úÖ submission.csv —Å–æ–∑–¥–∞–Ω –∏ –≥–æ—Ç–æ–≤ –∫ –∑–∞–≥—Ä—É–∑–∫–µ.\")\n",
    "\n",
    "# --- SHAP –∞–Ω–∞–ª–∏–∑ ---\n",
    "explainer = shap.TreeExplainer(model)\n",
    "X_train_full_prep = preprocessor.transform(X)\n",
    "shap_values = explainer.shap_values(X_train_full_prep)\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values_to_plot = shap_values[1]\n",
    "else:\n",
    "    shap_values_to_plot = shap_values\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values_to_plot,\n",
    "    X_train_full_prep,\n",
    "    feature_names=num_features + cat_features,\n",
    "    plot_type='bar'\n",
    ")\n",
    "\n",
    "# --- –ì—Ä–∞—Ñ–∏–∫ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ LightGBM ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "lgb.plot_importance(model, max_num_features=20, importance_type='gain')\n",
    "plt.title('–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ LightGBM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16476872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ LGBM –∏ RandomForest –ø–æ ROC –∏ –º–µ—Ç—Ä–∏–∫–∞–º ---\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def objective_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 4, 20)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)\n",
    "    max_features = trial.suggest_categorical(\n",
    "        'max_features', ['sqrt', 'log2', None])\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # 5-fold CV –ø–æ F1 (weighted –¥–ª—è –±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤)\n",
    "    scores = cross_val_score(\n",
    "        rf,\n",
    "        X_full_prep,  # —É–∂–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "        y,\n",
    "        cv=5,\n",
    "        scoring='f1'\n",
    "    )\n",
    "    return scores.mean()\n",
    "\n",
    "# –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –¥–ª—è —á–µ—Å—Ç–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
    "X_full_prep = preprocessor.fit_transform(X, y)\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(\n",
    "    X_full_prep, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# --- RandomForest ---\n",
    "best_rf_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=8,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1\n",
    ")\n",
    "best_rf_model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# --- LGBM (–¥–ª—è ROC —Å—Ä–∞–≤–Ω–µ–Ω–∏—è) ---\n",
    "# –ü–µ—Ä–µ–æ–±—É—á–∞–µ–º LGBM –Ω–∞ —Ç–æ–º –∂–µ split\n",
    "model_lgb = lgb.LGBMClassifier(**params, n_estimators=500)\n",
    "model_lgb.fit(X_train_split, y_train_split)\n",
    "\n",
    "# --- ROC –∏ –º–µ—Ç—Ä–∏–∫–∏ ---\n",
    "y_train_proba_lgb = model_lgb.predict_proba(X_train_split)[:, 1]\n",
    "y_test_proba_lgb = model_lgb.predict_proba(X_test_split)[:, 1]\n",
    "y_test_pred_lgb = (y_test_proba_lgb > best_thr).astype(int)\n",
    "\n",
    "y_train_proba_rf = best_rf_model.predict_proba(X_train_split)[:, 1]\n",
    "y_test_proba_rf = best_rf_model.predict_proba(X_test_split)[:, 1]\n",
    "y_test_pred_rf = (y_test_proba_rf > 0.5).astype(int)\n",
    "\n",
    "# --- ROC-–∫—Ä–∏–≤—ã–µ ---\n",
    "fpr_lgb, tpr_lgb, _ = roc_curve(y_test_split, y_test_proba_lgb)\n",
    "auc_lgb = roc_auc_score(y_test_split, y_test_proba_lgb)\n",
    "\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test_split, y_test_proba_rf)\n",
    "auc_rf = roc_auc_score(y_test_split, y_test_proba_rf)\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(fpr_lgb, tpr_lgb, label=f'LGBM (AUC = {auc_lgb:.3f})')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'RandomForest (AUC = {auc_rf:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ ROC-–∫—Ä–∏–≤—ã—Ö: LGBM vs RandomForest')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- –ú–µ—Ç—Ä–∏–∫–∏ ---\n",
    "acc_lgb = accuracy_score(y_test_split, y_test_pred_lgb)\n",
    "f1_lgb = f1_score(y_test_split, y_test_pred_lgb)\n",
    "\n",
    "acc_rf = accuracy_score(y_test_split, y_test_pred_rf)\n",
    "f1_rf = f1_score(y_test_split, y_test_pred_rf)\n",
    "\n",
    "print(\n",
    "    f\"‚úÖ LGBM: AUC = {auc_lgb:.4f}, Accuracy = {acc_lgb:.4f}, F1 = {f1_lgb:.4f}\")\n",
    "print(f\"‚úÖ RF  : AUC = {auc_rf:.4f}, Accuracy = {acc_rf:.4f}, F1 = {f1_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae04e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# --- –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---\n",
    "with zipfile.ZipFile('playground-series-s5e7.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "for df in [df_train, df_test]:\n",
    "    df['alone_ratio'] = df['Time_spent_Alone'] / (\n",
    "        df['Time_spent_Alone'] + df['Social_event_attendance'] + df['Going_outside'] + 1)\n",
    "    df['social_ratio'] = df['Social_event_attendance'] / \\\n",
    "        (df['Going_outside'] + 1)\n",
    "    df['is_high_poster'] = (df['Post_frequency'] > 5).astype(int)\n",
    "\n",
    "# --- –ö–æ–¥–∏—Ä–æ–≤–∫–∞ —Ç–∞—Ä–≥–µ—Ç–∞ ---\n",
    "target = 'Personality'\n",
    "label_encoder = LabelEncoder()\n",
    "df_train['target'] = label_encoder.fit_transform(df_train[target])\n",
    "\n",
    "# --- –ü—Ä–∏–∑–Ω–∞–∫–∏ ---\n",
    "num_features = ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside',\n",
    "                'Friends_circle_size', 'Post_frequency', 'alone_ratio', 'social_ratio']\n",
    "cat_features = ['Stage_fear', 'Drained_after_socializing', 'is_high_poster']\n",
    "\n",
    "X = df_train[num_features + cat_features]\n",
    "y = df_train['target']\n",
    "X_test = df_test[num_features + cat_features]\n",
    "\n",
    "# --- –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ ---\n",
    "cat_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('target_encoder', TargetEncoder())\n",
    "])\n",
    "num_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipe, num_features),\n",
    "    ('cat', cat_pipe, cat_features)\n",
    "])\n",
    "\n",
    "# --- Optuna –¥–ª—è LGBM ---\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'random_state': 42,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0, 5),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0, 5),\n",
    "    }\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, valid_idx in skf.split(X, y):\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_valid, y_valid = X.iloc[valid_idx], y.iloc[valid_idx]\n",
    "        X_train_prep = preprocessor.fit_transform(X_train, y_train)\n",
    "        X_valid_prep = preprocessor.transform(X_valid)\n",
    "\n",
    "        train_data = lgb.Dataset(X_train_prep, label=y_train)\n",
    "        valid_data = lgb.Dataset(X_valid_prep, label=y_valid)\n",
    "\n",
    "        model = lgb.train(params, train_data, valid_sets=[valid_data], num_boost_round=1000,\n",
    "                          callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)])\n",
    "\n",
    "        preds = (model.predict(X_valid_prep,\n",
    "                 num_iteration=model.best_iteration) > 0.5).astype(int)\n",
    "        scores.append(f1_score(y_valid, preds))\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "print(\"üöÄ Optuna LGBM –∑–∞–ø—É—Å–∫...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "print(f\"‚úÖ LGBM –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {study.best_params}\")\n",
    "print(f\"‚úÖ LGBM –ª—É—á—à–∏–π F1: {study.best_value:.4f}\")\n",
    "\n",
    "params = study.best_params\n",
    "params.update({'objective': 'binary', 'metric': 'binary_logloss',\n",
    "              'boosting_type': 'gbdt', 'random_state': 42})\n",
    "\n",
    "# --- Optuna –¥–ª—è RandomForest ---\n",
    "\n",
    "\n",
    "def objective_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 4, 20)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)\n",
    "    max_features = trial.suggest_categorical(\n",
    "        'max_features', ['sqrt', 'log2', None])\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    X_full_prep = preprocessor.fit_transform(X, y)\n",
    "    return cross_val_score(rf, X_full_prep, y, cv=3, scoring='f1').mean()\n",
    "\n",
    "\n",
    "print(\"\\nüöÄ Optuna RandomForest –∑–∞–ø—É—Å–∫...\")\n",
    "study_rf = optuna.create_study(direction='maximize')\n",
    "study_rf.optimize(objective_rf, n_trials=30)\n",
    "print(f\"‚úÖ RF –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {study_rf.best_params}\")\n",
    "print(f\"‚úÖ RF –ª—É—á—à–∏–π F1: {study_rf.best_value:.4f}\")\n",
    "\n",
    "# --- –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ ---\n",
    "X_full_prep = preprocessor.fit_transform(X, y)\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(\n",
    "    X_full_prep, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "best_rf_model = RandomForestClassifier(\n",
    "    **study_rf.best_params, class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "best_rf_model.fit(X_train_split, y_train_split)\n",
    "\n",
    "model_lgb = lgb.LGBMClassifier(**params, n_estimators=500)\n",
    "model_lgb.fit(X_train_split, y_train_split)\n",
    "\n",
    "# --- –ú–µ—Ç—Ä–∏–∫–∏ ---\n",
    "y_test_proba_lgb = model_lgb.predict_proba(X_test_split)[:, 1]\n",
    "y_test_proba_rf = best_rf_model.predict_proba(X_test_split)[:, 1]\n",
    "\n",
    "fpr_lgb, tpr_lgb, _ = roc_curve(y_test_split, y_test_proba_lgb)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test_split, y_test_proba_rf)\n",
    "auc_lgb = roc_auc_score(y_test_split, y_test_proba_lgb)\n",
    "auc_rf = roc_auc_score(y_test_split, y_test_proba_rf)\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(fpr_lgb, tpr_lgb, label=f'LGBM (AUC = {auc_lgb:.3f})')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'RF (AUC = {auc_rf:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-–∫—Ä–∏–≤–∞—è: LGBM vs RandomForest')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ ---\n",
    "y_test_pred_lgb = (y_test_proba_lgb > 0.5).astype(int)\n",
    "y_test_pred_rf = (y_test_proba_rf > 0.5).astype(int)\n",
    "\n",
    "print(f\"‚úÖ LGBM: AUC = {auc_lgb:.4f}, Accuracy = {accuracy_score(y_test_split, y_test_pred_lgb):.4f}, F1 = {f1_score(y_test_split, y_test_pred_lgb):.4f}\")\n",
    "print(f\"‚úÖ RF  : AUC = {auc_rf:.4f}, Accuracy = {accuracy_score(y_test_split, y_test_pred_rf):.4f}, F1 = {f1_score(y_test_split, y_test_pred_rf):.4f}\")\n",
    "\n",
    "# SHAP –∞–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "explainer = shap.TreeExplainer(model)\n",
    "X_train_full_prep = preprocessor.transform(X)\n",
    "\n",
    "shap_values = explainer.shap_values(X_train_full_prep)\n",
    "\n",
    "# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ shap_values\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values_to_plot = shap_values[1]  # –î–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
    "else:\n",
    "    shap_values_to_plot = shap_values\n",
    "\n",
    "print(f\"SHAP shape: {shap_values_to_plot.shape}\")\n",
    "\n",
    "# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞\n",
    "shap.summary_plot(\n",
    "    shap_values_to_plot,\n",
    "    X_train_full_prep,\n",
    "    feature_names=num_features + cat_features,\n",
    "    plot_type='bar'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53acd86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# --- 1. –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---\n",
    "with zipfile.ZipFile('playground-series-s5e7.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# --- 2. Feature Engineering ---\n",
    "for df in [df_train, df_test]:\n",
    "    df['alone_ratio'] = df['Time_spent_Alone'] / (\n",
    "        df['Time_spent_Alone'] + df['Social_event_attendance'] +\n",
    "        df['Going_outside'] + 1\n",
    "    )\n",
    "    df['social_ratio'] = df['Social_event_attendance'] / \\\n",
    "        (df['Going_outside'] + 1)\n",
    "    df['is_high_poster'] = (df['Post_frequency'] > 5).astype(int)\n",
    "\n",
    "# --- 3. –ö–æ–¥–∏—Ä–æ–≤–∫–∞ —Ç–∞—Ä–≥–µ—Ç–∞ ---\n",
    "target_col = 'Personality'\n",
    "label_encoder = LabelEncoder()\n",
    "df_train['target'] = label_encoder.fit_transform(df_train[target_col])\n",
    "\n",
    "# --- 4. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ---\n",
    "num_features = [\n",
    "    'Time_spent_Alone',\n",
    "    'Social_event_attendance',\n",
    "    'Going_outside',\n",
    "    'Friends_circle_size',\n",
    "    'Post_frequency',\n",
    "    'alone_ratio',\n",
    "    'social_ratio'\n",
    "]\n",
    "\n",
    "cat_features = [\n",
    "    'Stage_fear',\n",
    "    'Drained_after_socializing',\n",
    "    'is_high_poster'\n",
    "]\n",
    "\n",
    "X = df_train[num_features + cat_features]\n",
    "y = df_train['target']\n",
    "X_test = df_test[num_features + cat_features]\n",
    "\n",
    "# --- 5. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ---\n",
    "cat_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    # –¥–æ–±–∞–≤–∏–ª smoothing –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
    "    ('target_encoder', TargetEncoder(smoothing=0.3))\n",
    "])\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipe, num_features),\n",
    "    ('cat', cat_pipe, cat_features)\n",
    "])\n",
    "\n",
    "# --- 6. Optuna: –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ LightGBM ---\n",
    "\n",
    "\n",
    "def objective_lgb(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'random_state': 42,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0, 5),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0, 5),\n",
    "    }\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_idx, valid_idx in skf.split(X, y):\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_valid, y_valid = X.iloc[valid_idx], y.iloc[valid_idx]\n",
    "\n",
    "        # –§–∏—Ç–∏–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Ç–æ–ª—å–∫–æ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ\n",
    "        X_train_prep = preprocessor.fit_transform(X_train, y_train)\n",
    "        X_valid_prep = preprocessor.transform(X_valid)\n",
    "\n",
    "        train_data = lgb.Dataset(X_train_prep, label=y_train)\n",
    "        valid_data = lgb.Dataset(X_valid_prep, label=y_valid)\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets=[valid_data],\n",
    "            num_boost_round=1000,\n",
    "            callbacks=[lgb.early_stopping(50)]\n",
    "        )\n",
    "\n",
    "        preds = (model.predict(X_valid_prep,\n",
    "                 num_iteration=model.best_iteration) > 0.5).astype(int)\n",
    "        f1_scores.append(f1_score(y_valid, preds))\n",
    "\n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "\n",
    "print(\"üöÄ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ LightGBM...\")\n",
    "study_lgb = optuna.create_study(\n",
    "    direction='maximize', study_name='lgbm_f1_optimization')\n",
    "study_lgb.optimize(objective_lgb, n_trials=30)\n",
    "print(f\"‚úÖ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã LightGBM: {study_lgb.best_params}\")\n",
    "print(f\"‚úÖ –õ—É—á—à–∏–π F1 LightGBM: {study_lgb.best_value:.4f}\")\n",
    "\n",
    "lgb_params = study_lgb.best_params.copy()\n",
    "lgb_params.update({'objective': 'binary', 'metric': 'binary_logloss',\n",
    "                  'boosting_type': 'gbdt', 'random_state': 42})\n",
    "\n",
    "# --- 7. Optuna: –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ RandomForest ---\n",
    "\n",
    "\n",
    "def objective_rf(trial):\n",
    "    rf_params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 20),\n",
    "        'verbosity': -1,\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "        'class_weight': 'balanced',\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    X_full_prep = preprocessor.fit_transform(X, y)\n",
    "    rf = RandomForestClassifier(**rf_params)\n",
    "    return cross_val_score(rf, X_full_prep, y, cv=3, scoring='f1').mean()\n",
    "\n",
    "\n",
    "print(\"\\nüöÄ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ RandomForest...\")\n",
    "study_rf = optuna.create_study(\n",
    "    direction='maximize', study_name='rf_f1_optimization')\n",
    "study_rf.optimize(objective_rf, n_trials=30)\n",
    "print(f\"‚úÖ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã RandomForest: {study_rf.best_params}\")\n",
    "print(f\"‚úÖ –õ—É—á—à–∏–π F1 RandomForest: {study_rf.best_value:.4f}\")\n",
    "\n",
    "# --- 8. –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π ---\n",
    "X_full_prep = preprocessor.fit_transform(X, y)\n",
    "X_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(\n",
    "    X_full_prep, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# –û–±—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é RF –º–æ–¥–µ–ª—å\n",
    "best_rf_params = study_rf.best_params.copy()\n",
    "best_rf_model = RandomForestClassifier(\n",
    "    **best_rf_params, class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "best_rf_model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# –û–±—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é LGBM –º–æ–¥–µ–ª—å (sklearn API)\n",
    "model_lgb = lgb.LGBMClassifier(**lgb_params, n_estimators=500)\n",
    "model_lgb.fit(X_train_split, y_train_split)\n",
    "\n",
    "# --- 9. –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º —Å–ø–ª–∏—Ç–µ ---\n",
    "y_pred_proba_lgb = model_lgb.predict_proba(X_valid_split)[:, 1]\n",
    "y_pred_proba_rf = best_rf_model.predict_proba(X_valid_split)[:, 1]\n",
    "\n",
    "fpr_lgb, tpr_lgb, _ = roc_curve(y_valid_split, y_pred_proba_lgb)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_valid_split, y_pred_proba_rf)\n",
    "\n",
    "auc_lgb = roc_auc_score(y_valid_split, y_pred_proba_lgb)\n",
    "auc_rf = roc_auc_score(y_valid_split, y_pred_proba_rf)\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(fpr_lgb, tpr_lgb, label=f'LGBM (AUC = {auc_lgb:.3f})')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'RandomForest (AUC = {auc_rf:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-–∫—Ä–∏–≤–∞—è: LGBM vs RandomForest')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- 10. –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ ---\n",
    "y_pred_lgb = (y_pred_proba_lgb > 0.5).astype(int)\n",
    "y_pred_rf = (y_pred_proba_rf > 0.5).astype(int)\n",
    "\n",
    "print(f\"‚úÖ LGBM: AUC = {auc_lgb:.4f}, Accuracy = {accuracy_score(y_valid_split, y_pred_lgb):.4f}, F1 = {f1_score(y_valid_split, y_pred_lgb):.4f}\")\n",
    "print(f\"‚úÖ RF  : AUC = {auc_rf:.4f}, Accuracy = {accuracy_score(y_valid_split, y_pred_rf):.4f}, F1 = {f1_score(y_valid_split, y_pred_rf):.4f}\")\n",
    "\n",
    "# --- 11. SHAP-–∞–Ω–∞–ª–∏–∑ (LightGBM sklearn API) ---\n",
    "explainer = shap.Explainer(model_lgb)\n",
    "shap_values = explainer(X_full_prep)\n",
    "\n",
    "X_prep_df = pd.DataFrame(X_full_prep, columns=num_features + cat_features)\n",
    "\n",
    "shap.summary_plot(shap_values, features=X_prep_df, plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bdd3700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antontravkin/Sites/python_rtk/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-07-18 17:54:32,386] A new study created in memory with name: lgbm_f1_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ LightGBM...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[372]\tvalid_0's binary_logloss: 0.129921\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[259]\tvalid_0's binary_logloss: 0.136232\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:54:35,750] Trial 0 finished with value: 0.9397796186308222 and parameters: {'learning_rate': 0.018841865000372528, 'num_leaves': 23, 'max_depth': 5, 'feature_fraction': 0.7750323703275586, 'bagging_fraction': 0.9924925409455443, 'bagging_freq': 6, 'lambda_l1': 2.0563234574334324, 'lambda_l2': 3.083987652774656}. Best is trial 0 with value: 0.9397796186308222.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[297]\tvalid_0's binary_logloss: 0.123731\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[264]\tvalid_0's binary_logloss: 0.12991\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's binary_logloss: 0.136285\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:54:38,637] Trial 1 finished with value: 0.9398055867362812 and parameters: {'learning_rate': 0.022313064374720925, 'num_leaves': 40, 'max_depth': 6, 'feature_fraction': 0.8034408855886714, 'bagging_fraction': 0.6906781318872681, 'bagging_freq': 8, 'lambda_l1': 2.8197729343208455, 'lambda_l2': 0.04867075601451609}. Best is trial 1 with value: 0.9398055867362812.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's binary_logloss: 0.123872\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's binary_logloss: 0.130127\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's binary_logloss: 0.136157\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:54:41,538] Trial 2 finished with value: 0.9400015502970849 and parameters: {'learning_rate': 0.04738689953834103, 'num_leaves': 59, 'max_depth': 11, 'feature_fraction': 0.7827921070714139, 'bagging_fraction': 0.7184263069173575, 'bagging_freq': 2, 'lambda_l1': 1.687155922734322, 'lambda_l2': 2.9907316114929565}. Best is trial 2 with value: 0.9400015502970849.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's binary_logloss: 0.123957\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[506]\tvalid_0's binary_logloss: 0.129902\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[350]\tvalid_0's binary_logloss: 0.136034\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:54:48,038] Trial 3 finished with value: 0.9400847878867973 and parameters: {'learning_rate': 0.01328080219710985, 'num_leaves': 43, 'max_depth': 9, 'feature_fraction': 0.8061860060227325, 'bagging_fraction': 0.9324465477722028, 'bagging_freq': 9, 'lambda_l1': 3.2175804811276527, 'lambda_l2': 0.01153837188966167}. Best is trial 3 with value: 0.9400847878867973.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[430]\tvalid_0's binary_logloss: 0.123621\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[484]\tvalid_0's binary_logloss: 0.130134\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[389]\tvalid_0's binary_logloss: 0.136025\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:54:55,022] Trial 4 finished with value: 0.9397926392823216 and parameters: {'learning_rate': 0.012318185690021294, 'num_leaves': 59, 'max_depth': 9, 'feature_fraction': 0.8924856896976399, 'bagging_fraction': 0.6333279263420571, 'bagging_freq': 4, 'lambda_l1': 1.9333657948132794, 'lambda_l2': 2.317597854682396}. Best is trial 3 with value: 0.9400847878867973.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[404]\tvalid_0's binary_logloss: 0.124404\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's binary_logloss: 0.129432\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's binary_logloss: 0.136177\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:54:56,306] Trial 5 finished with value: 0.940162765852571 and parameters: {'learning_rate': 0.07195360877725514, 'num_leaves': 53, 'max_depth': 5, 'feature_fraction': 0.6180898310541443, 'bagging_fraction': 0.6500889875446622, 'bagging_freq': 9, 'lambda_l1': 0.7565431971208131, 'lambda_l2': 2.6996946330536256}. Best is trial 5 with value: 0.940162765852571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's binary_logloss: 0.12363\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[305]\tvalid_0's binary_logloss: 0.129768\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[178]\tvalid_0's binary_logloss: 0.135709\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:54:59,246] Trial 6 finished with value: 0.9400395293381245 and parameters: {'learning_rate': 0.03324536631025935, 'num_leaves': 85, 'max_depth': 10, 'feature_fraction': 0.6058317804682748, 'bagging_fraction': 0.6762289506699961, 'bagging_freq': 5, 'lambda_l1': 3.6972787144915316, 'lambda_l2': 4.904359159950713}. Best is trial 5 with value: 0.940162765852571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[202]\tvalid_0's binary_logloss: 0.123434\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[301]\tvalid_0's binary_logloss: 0.129609\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's binary_logloss: 0.136155\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:55:01,179] Trial 7 finished with value: 0.9399035378973767 and parameters: {'learning_rate': 0.02452877671317121, 'num_leaves': 31, 'max_depth': 4, 'feature_fraction': 0.9098477184940965, 'bagging_fraction': 0.6576940213882952, 'bagging_freq': 4, 'lambda_l1': 0.008106643526042956, 'lambda_l2': 3.9130118024892067}. Best is trial 5 with value: 0.940162765852571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's binary_logloss: 0.124266\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[419]\tvalid_0's binary_logloss: 0.129721\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[308]\tvalid_0's binary_logloss: 0.135975\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:55:05,309] Trial 8 finished with value: 0.9402097535034143 and parameters: {'learning_rate': 0.017072665400123806, 'num_leaves': 32, 'max_depth': 6, 'feature_fraction': 0.6631582600581258, 'bagging_fraction': 0.9289615633367633, 'bagging_freq': 1, 'lambda_l1': 3.311947707959175, 'lambda_l2': 1.4569912147350954}. Best is trial 8 with value: 0.9402097535034143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[382]\tvalid_0's binary_logloss: 0.123759\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's binary_logloss: 0.130529\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's binary_logloss: 0.137285\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:55:08,664] Trial 9 finished with value: 0.9396679909303662 and parameters: {'learning_rate': 0.025812743503543185, 'num_leaves': 34, 'max_depth': 8, 'feature_fraction': 0.9005358763379769, 'bagging_fraction': 0.7941820667231352, 'bagging_freq': 1, 'lambda_l1': 0.6626961361230727, 'lambda_l2': 0.148365748413834}. Best is trial 8 with value: 0.9402097535034143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's binary_logloss: 0.124938\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[987]\tvalid_0's binary_logloss: 0.129173\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[574]\tvalid_0's binary_logloss: 0.136293\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:55:12,252] Trial 10 finished with value: 0.9401123796654245 and parameters: {'learning_rate': 0.010676632008486, 'num_leaves': 82, 'max_depth': 3, 'feature_fraction': 0.6892308769450365, 'bagging_fraction': 0.8634953591924165, 'bagging_freq': 2, 'lambda_l1': 4.21216873747538, 'lambda_l2': 1.2254750290952314}. Best is trial 8 with value: 0.9402097535034143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[682]\tvalid_0's binary_logloss: 0.12373\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's binary_logloss: 0.130496\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's binary_logloss: 0.136732\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:55:14,342] Trial 11 finished with value: 0.9401255758130823 and parameters: {'learning_rate': 0.09367238786745828, 'num_leaves': 51, 'max_depth': 7, 'feature_fraction': 0.6010670992038158, 'bagging_fraction': 0.7740520702661302, 'bagging_freq': 10, 'lambda_l1': 0.9776056428351367, 'lambda_l2': 1.6938569473425635}. Best is trial 8 with value: 0.9402097535034143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's binary_logloss: 0.12423\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's binary_logloss: 0.129475\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's binary_logloss: 0.13612\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:55:16,046] Trial 12 finished with value: 0.9400388299380538 and parameters: {'learning_rate': 0.09115042762013328, 'num_leaves': 77, 'max_depth': 6, 'feature_fraction': 0.679874819777838, 'bagging_fraction': 0.8716591604893789, 'bagging_freq': 7, 'lambda_l1': 4.857353886136769, 'lambda_l2': 1.2639099467223907}. Best is trial 8 with value: 0.9402097535034143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's binary_logloss: 0.123839\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's binary_logloss: 0.12976\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's binary_logloss: 0.136264\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:55:18,272] Trial 13 finished with value: 0.9400009726156547 and parameters: {'learning_rate': 0.060446503109065346, 'num_leaves': 100, 'max_depth': 5, 'feature_fraction': 0.6802358620413486, 'bagging_fraction': 0.886329928511003, 'bagging_freq': 8, 'lambda_l1': 2.7176200787068634, 'lambda_l2': 2.243162384562819}. Best is trial 8 with value: 0.9402097535034143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's binary_logloss: 0.124066\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[246]\tvalid_0's binary_logloss: 0.12955\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's binary_logloss: 0.135995\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:55:19,573] Trial 14 finished with value: 0.9400143672657162 and parameters: {'learning_rate': 0.04458805276184861, 'num_leaves': 50, 'max_depth': 3, 'feature_fraction': 0.9931152336687703, 'bagging_fraction': 0.6033480959011922, 'bagging_freq': 3, 'lambda_l1': 3.7121925936685503, 'lambda_l2': 3.5884527856865813}. Best is trial 8 with value: 0.9402097535034143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's binary_logloss: 0.123998\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[341]\tvalid_0's binary_logloss: 0.129717\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[287]\tvalid_0's binary_logloss: 0.135817\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:55:23,827] Trial 15 finished with value: 0.9400264114156555 and parameters: {'learning_rate': 0.0161736250859594, 'num_leaves': 23, 'max_depth': 7, 'feature_fraction': 0.6482907631930636, 'bagging_fraction': 0.7410434999347775, 'bagging_freq': 10, 'lambda_l1': 1.080621785487548, 'lambda_l2': 0.8690934093705721}. Best is trial 8 with value: 0.9402097535034143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[314]\tvalid_0's binary_logloss: 0.12375\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's binary_logloss: 0.130956\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's binary_logloss: 0.136921\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:55:28,004] Trial 16 finished with value: 0.9397919884440418 and parameters: {'learning_rate': 0.03579565238363738, 'num_leaves': 66, 'max_depth': 12, 'feature_fraction': 0.7372464062738422, 'bagging_fraction': 0.9903374330029214, 'bagging_freq': 6, 'lambda_l1': 0.05851695423930259, 'lambda_l2': 1.859736187579111}. Best is trial 8 with value: 0.9402097535034143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's binary_logloss: 0.125425\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's binary_logloss: 0.129405\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's binary_logloss: 0.135804\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:55:29,359] Trial 17 finished with value: 0.9399035378973767 and parameters: {'learning_rate': 0.06527049233814453, 'num_leaves': 67, 'max_depth': 5, 'feature_fraction': 0.7193015427226195, 'bagging_fraction': 0.8245566581171991, 'bagging_freq': 1, 'lambda_l1': 2.3383899940443884, 'lambda_l2': 2.7962409914444706}. Best is trial 8 with value: 0.9402097535034143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's binary_logloss: 0.123793\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's binary_logloss: 0.129439\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's binary_logloss: 0.135741\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:55:31,289] Trial 18 finished with value: 0.9401243625767509 and parameters: {'learning_rate': 0.06970872784893033, 'num_leaves': 45, 'max_depth': 6, 'feature_fraction': 0.6429581341319968, 'bagging_fraction': 0.9327104669223769, 'bagging_freq': 7, 'lambda_l1': 1.5278969984463453, 'lambda_l2': 3.967177663775179}. Best is trial 8 with value: 0.9402097535034143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's binary_logloss: 0.123658\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[593]\tvalid_0's binary_logloss: 0.129148\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[300]\tvalid_0's binary_logloss: 0.135732\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:55:34,301] Trial 19 finished with value: 0.9403338309212268 and parameters: {'learning_rate': 0.018207728716790647, 'num_leaves': 31, 'max_depth': 4, 'feature_fraction': 0.6376410214445216, 'bagging_fraction': 0.7503112244306667, 'bagging_freq': 5, 'lambda_l1': 3.3954378558850227, 'lambda_l2': 0.8472293826237782}. Best is trial 19 with value: 0.9403338309212268.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[357]\tvalid_0's binary_logloss: 0.123573\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[581]\tvalid_0's binary_logloss: 0.129511\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[333]\tvalid_0's binary_logloss: 0.135964\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:55:37,154] Trial 20 finished with value: 0.9401123796654245 and parameters: {'learning_rate': 0.01674896257919611, 'num_leaves': 32, 'max_depth': 4, 'feature_fraction': 0.7367049001286108, 'bagging_fraction': 0.8370245839085179, 'bagging_freq': 4, 'lambda_l1': 4.921663558506509, 'lambda_l2': 0.5971033832099351}. Best is trial 19 with value: 0.9403338309212268.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[353]\tvalid_0's binary_logloss: 0.123644\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[521]\tvalid_0's binary_logloss: 0.129213\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[298]\tvalid_0's binary_logloss: 0.135782\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:55:40,259] Trial 21 finished with value: 0.9403332006939591 and parameters: {'learning_rate': 0.019516981746073744, 'num_leaves': 22, 'max_depth': 4, 'feature_fraction': 0.6360600736175013, 'bagging_fraction': 0.7597982413253331, 'bagging_freq': 5, 'lambda_l1': 3.2761049866255387, 'lambda_l2': 1.5963016393809977}. Best is trial 19 with value: 0.9403338309212268.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[309]\tvalid_0's binary_logloss: 0.123588\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[420]\tvalid_0's binary_logloss: 0.129274\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[300]\tvalid_0's binary_logloss: 0.135726\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:55:42,962] Trial 22 finished with value: 0.9399416393582665 and parameters: {'learning_rate': 0.02010499804864341, 'num_leaves': 20, 'max_depth': 4, 'feature_fraction': 0.6437612872802227, 'bagging_fraction': 0.7527633293283293, 'bagging_freq': 5, 'lambda_l1': 3.3222309560096703, 'lambda_l2': 1.6024334530068025}. Best is trial 19 with value: 0.9403338309212268.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[344]\tvalid_0's binary_logloss: 0.123624\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[870]\tvalid_0's binary_logloss: 0.129295\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[416]\tvalid_0's binary_logloss: 0.136203\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:55:46,069] Trial 23 finished with value: 0.9401251274521779 and parameters: {'learning_rate': 0.014570187044105223, 'num_leaves': 29, 'max_depth': 3, 'feature_fraction': 0.7005388385322993, 'bagging_fraction': 0.7084384376963857, 'bagging_freq': 3, 'lambda_l1': 4.09196133196879, 'lambda_l2': 0.7587400701801811}. Best is trial 19 with value: 0.9403338309212268.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[520]\tvalid_0's binary_logloss: 0.123949\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[363]\tvalid_0's binary_logloss: 0.129319\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[232]\tvalid_0's binary_logloss: 0.135892\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:55:48,441] Trial 24 finished with value: 0.94011187123071 and parameters: {'learning_rate': 0.0270697952024369, 'num_leaves': 39, 'max_depth': 4, 'feature_fraction': 0.6520046733692066, 'bagging_fraction': 0.8111841461965248, 'bagging_freq': 3, 'lambda_l1': 3.1613134733187946, 'lambda_l2': 1.1862706802921492}. Best is trial 19 with value: 0.9403338309212268.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's binary_logloss: 0.123539\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[725]\tvalid_0's binary_logloss: 0.12939\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[525]\tvalid_0's binary_logloss: 0.135892\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:55:57,616] Trial 25 finished with value: 0.9402223749764591 and parameters: {'learning_rate': 0.010158191098048901, 'num_leaves': 28, 'max_depth': 6, 'feature_fraction': 0.7545663502979559, 'bagging_fraction': 0.768955662265677, 'bagging_freq': 5, 'lambda_l1': 4.287616289746362, 'lambda_l2': 1.9573412749551617}. Best is trial 19 with value: 0.9403338309212268.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[625]\tvalid_0's binary_logloss: 0.12377\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[725]\tvalid_0's binary_logloss: 0.129456\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[525]\tvalid_0's binary_logloss: 0.135974\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:56:10,226] Trial 26 finished with value: 0.9397926392823216 and parameters: {'learning_rate': 0.010024602699516048, 'num_leaves': 26, 'max_depth': 7, 'feature_fraction': 0.8700178750648823, 'bagging_fraction': 0.7719473887113398, 'bagging_freq': 5, 'lambda_l1': 4.424804995640062, 'lambda_l2': 1.993766390256305}. Best is trial 19 with value: 0.9403338309212268.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[625]\tvalid_0's binary_logloss: 0.123877\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[714]\tvalid_0's binary_logloss: 0.129314\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[471]\tvalid_0's binary_logloss: 0.135836\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:56:17,242] Trial 27 finished with value: 0.9399035378973767 and parameters: {'learning_rate': 0.012826705071944736, 'num_leaves': 20, 'max_depth': 4, 'feature_fraction': 0.8477639794463531, 'bagging_fraction': 0.7347456276048089, 'bagging_freq': 6, 'lambda_l1': 3.6707921390172427, 'lambda_l2': 0.421247023137131}. Best is trial 19 with value: 0.9403338309212268.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[528]\tvalid_0's binary_logloss: 0.123607\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[429]\tvalid_0's binary_logloss: 0.129581\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[267]\tvalid_0's binary_logloss: 0.136168\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:56:20,283] Trial 28 finished with value: 0.9397926392823216 and parameters: {'learning_rate': 0.029387789282351206, 'num_leaves': 38, 'max_depth': 3, 'feature_fraction': 0.7585675776826317, 'bagging_fraction': 0.7824914068392186, 'bagging_freq': 7, 'lambda_l1': 4.465155506052218, 'lambda_l2': 0.9913036826528949}. Best is trial 19 with value: 0.9403338309212268.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[246]\tvalid_0's binary_logloss: 0.12367\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[419]\tvalid_0's binary_logloss: 0.129564\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[312]\tvalid_0's binary_logloss: 0.136268\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-18 17:56:27,205] Trial 29 finished with value: 0.9396679909303662 and parameters: {'learning_rate': 0.019824586483995436, 'num_leaves': 25, 'max_depth': 5, 'feature_fraction': 0.9518681417960154, 'bagging_fraction': 0.7518733890623551, 'bagging_freq': 6, 'lambda_l1': 3.9440612167972415, 'lambda_l2': 2.028774519152736}. Best is trial 19 with value: 0.9403338309212268.\n",
      "[I 2025-07-18 17:56:27,208] A new study created in memory with name: rf_f1_optimization\n",
      "[W 2025-07-18 17:56:27,292] Trial 0 failed with parameters: {'n_estimators': 160, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'log2'} because of the following error: TypeError(\"RandomForestClassifier.__init__() got an unexpected keyword argument 'verbosity'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antontravkin/Sites/python_rtk/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/94/mhtjzffs5fvgmwqpgnt1qb6w0000gn/T/ipykernel_23042/1412765155.py\", line 153, in objective_rf\n",
      "    rf = RandomForestClassifier(**rf_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: RandomForestClassifier.__init__() got an unexpected keyword argument 'verbosity'\n",
      "[W 2025-07-18 17:56:27,295] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[330]\tvalid_0's binary_logloss: 0.123703\n",
      "‚úÖ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã LightGBM: {'learning_rate': 0.018207728716790647, 'num_leaves': 31, 'max_depth': 4, 'feature_fraction': 0.6376410214445216, 'bagging_fraction': 0.7503112244306667, 'bagging_freq': 5, 'lambda_l1': 3.3954378558850227, 'lambda_l2': 0.8472293826237782}\n",
      "‚úÖ –õ—É—á—à–∏–π F1 LightGBM: 0.9403\n",
      "\n",
      "üöÄ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ RandomForest...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "RandomForestClassifier.__init__() got an unexpected keyword argument 'verbosity'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 160\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müöÄ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ RandomForest...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    158\u001b[39m study_rf = optuna.create_study(\n\u001b[32m    159\u001b[39m     direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m, study_name=\u001b[33m'\u001b[39m\u001b[33mrf_f1_optimization\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m \u001b[43mstudy_rf\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_rf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã RandomForest: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy_rf.best_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    162\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ –õ—É—á—à–∏–π F1 RandomForest: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy_rf.best_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Sites/python_rtk/.venv/lib/python3.12/site-packages/optuna/study/study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Sites/python_rtk/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Sites/python_rtk/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Sites/python_rtk/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Sites/python_rtk/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 153\u001b[39m, in \u001b[36mobjective_rf\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    141\u001b[39m rf_params = {\n\u001b[32m    142\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_int(\u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m100\u001b[39m, \u001b[32m500\u001b[39m),\n\u001b[32m    143\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_int(\u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m20\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m    150\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mn_jobs\u001b[39m\u001b[33m'\u001b[39m: -\u001b[32m1\u001b[39m\n\u001b[32m    151\u001b[39m }\n\u001b[32m    152\u001b[39m X_full_prep = preprocessor.fit_transform(X, y)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m rf = \u001b[43mRandomForestClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrf_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cross_val_score(rf, X_full_prep, y, cv=\u001b[32m3\u001b[39m, scoring=\u001b[33m'\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m'\u001b[39m).mean()\n",
      "\u001b[31mTypeError\u001b[39m: RandomForestClassifier.__init__() got an unexpected keyword argument 'verbosity'"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# --- 1. –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---\n",
    "with zipfile.ZipFile('playground-series-s5e7.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# --- 2. Feature Engineering ---\n",
    "for df in [df_train, df_test]:\n",
    "    df['alone_ratio'] = df['Time_spent_Alone'] / (\n",
    "        df['Time_spent_Alone'] + df['Social_event_attendance'] +\n",
    "        df['Going_outside'] + 1\n",
    "    )\n",
    "    df['social_ratio'] = df['Social_event_attendance'] / \\\n",
    "        (df['Going_outside'] + 1)\n",
    "    df['is_high_poster'] = (df['Post_frequency'] > 5).astype(int)\n",
    "\n",
    "# --- 3. –ö–æ–¥–∏—Ä–æ–≤–∫–∞ —Ç–∞—Ä–≥–µ—Ç–∞ ---\n",
    "target_col = 'Personality'\n",
    "label_encoder = LabelEncoder()\n",
    "df_train['target'] = label_encoder.fit_transform(df_train[target_col])\n",
    "\n",
    "# --- 4. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ---\n",
    "num_features = [\n",
    "    'Time_spent_Alone',\n",
    "    'Social_event_attendance',\n",
    "    'Going_outside',\n",
    "    'Friends_circle_size',\n",
    "    'Post_frequency',\n",
    "    'alone_ratio',\n",
    "    'social_ratio'\n",
    "]\n",
    "\n",
    "cat_features = [\n",
    "    'Stage_fear',\n",
    "    'Drained_after_socializing',\n",
    "    'is_high_poster'\n",
    "]\n",
    "\n",
    "X = df_train[num_features + cat_features]\n",
    "y = df_train['target']\n",
    "X_test = df_test[num_features + cat_features]\n",
    "\n",
    "# --- 5. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ---\n",
    "cat_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    # –¥–æ–±–∞–≤–∏–ª smoothing –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
    "    ('target_encoder', TargetEncoder(smoothing=0.3))\n",
    "])\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipe, num_features),\n",
    "    ('cat', cat_pipe, cat_features)\n",
    "])\n",
    "\n",
    "# --- 6. Optuna: –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ LightGBM ---\n",
    "\n",
    "\n",
    "def objective_lgb(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'random_state': 42,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0, 5),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0, 5),\n",
    "    }\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_idx, valid_idx in skf.split(X, y):\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_valid, y_valid = X.iloc[valid_idx], y.iloc[valid_idx]\n",
    "\n",
    "        # –§–∏—Ç–∏–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Ç–æ–ª—å–∫–æ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ\n",
    "        X_train_prep = preprocessor.fit_transform(X_train, y_train)\n",
    "        X_valid_prep = preprocessor.transform(X_valid)\n",
    "\n",
    "        train_data = lgb.Dataset(X_train_prep, label=y_train)\n",
    "        valid_data = lgb.Dataset(X_valid_prep, label=y_valid)\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets=[valid_data],\n",
    "            num_boost_round=1000,\n",
    "            callbacks=[lgb.early_stopping(50)]\n",
    "        )\n",
    "\n",
    "        preds = (model.predict(X_valid_prep,\n",
    "                 num_iteration=model.best_iteration) > 0.5).astype(int)\n",
    "        f1_scores.append(f1_score(y_valid, preds))\n",
    "\n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "\n",
    "print(\"üöÄ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ LightGBM...\")\n",
    "study_lgb = optuna.create_study(\n",
    "    direction='maximize', study_name='lgbm_f1_optimization')\n",
    "study_lgb.optimize(objective_lgb, n_trials=30)\n",
    "print(f\"‚úÖ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã LightGBM: {study_lgb.best_params}\")\n",
    "print(f\"‚úÖ –õ—É—á—à–∏–π F1 LightGBM: {study_lgb.best_value:.4f}\")\n",
    "\n",
    "lgb_params = study_lgb.best_params.copy()\n",
    "lgb_params.update({'objective': 'binary', 'metric': 'binary_logloss',\n",
    "                  'boosting_type': 'gbdt', 'random_state': 42})\n",
    "\n",
    "# --- 7. Optuna: –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ RandomForest ---\n",
    "\n",
    "\n",
    "def objective_rf(trial):\n",
    "    rf_params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 20),\n",
    "        'verbosity': -1,\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "        'class_weight': 'balanced',\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    X_full_prep = preprocessor.fit_transform(X, y)\n",
    "    rf = RandomForestClassifier(**rf_params)\n",
    "    return cross_val_score(rf, X_full_prep, y, cv=3, scoring='f1').mean()\n",
    "\n",
    "\n",
    "print(\"\\nüöÄ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ RandomForest...\")\n",
    "study_rf = optuna.create_study(\n",
    "    direction='maximize', study_name='rf_f1_optimization')\n",
    "study_rf.optimize(objective_rf, n_trials=30)\n",
    "print(f\"‚úÖ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã RandomForest: {study_rf.best_params}\")\n",
    "print(f\"‚úÖ –õ—É—á—à–∏–π F1 RandomForest: {study_rf.best_value:.4f}\")\n",
    "\n",
    "# --- 8. –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π ---\n",
    "X_full_prep = preprocessor.fit_transform(X, y)\n",
    "X_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(\n",
    "    X_full_prep, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# –û–±—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é RF –º–æ–¥–µ–ª—å\n",
    "best_rf_params = study_rf.best_params.copy()\n",
    "best_rf_model = RandomForestClassifier(\n",
    "    **best_rf_params, class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "best_rf_model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# –û–±—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é LGBM –º–æ–¥–µ–ª—å (sklearn API)\n",
    "model_lgb = lgb.LGBMClassifier(**lgb_params, n_estimators=500)\n",
    "model_lgb.fit(X_train_split, y_train_split)\n",
    "\n",
    "# --- 9. –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º —Å–ø–ª–∏—Ç–µ ---\n",
    "y_pred_proba_lgb = model_lgb.predict_proba(X_valid_split)[:, 1]\n",
    "y_pred_proba_rf = best_rf_model.predict_proba(X_valid_split)[:, 1]\n",
    "\n",
    "fpr_lgb, tpr_lgb, _ = roc_curve(y_valid_split, y_pred_proba_lgb)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_valid_split, y_pred_proba_rf)\n",
    "\n",
    "auc_lgb = roc_auc_score(y_valid_split, y_pred_proba_lgb)\n",
    "auc_rf = roc_auc_score(y_valid_split, y_pred_proba_rf)\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(fpr_lgb, tpr_lgb, label=f'LGBM (AUC = {auc_lgb:.3f})')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'RandomForest (AUC = {auc_rf:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-–∫—Ä–∏–≤–∞—è: LGBM vs RandomForest')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- 10. –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ ---\n",
    "y_pred_lgb = (y_pred_proba_lgb > 0.5).astype(int)\n",
    "y_pred_rf = (y_pred_proba_rf > 0.5).astype(int)\n",
    "\n",
    "print(f\"‚úÖ LGBM: AUC = {auc_lgb:.4f}, Accuracy = {accuracy_score(y_valid_split, y_pred_lgb):.4f}, F1 = {f1_score(y_valid_split, y_pred_lgb):.4f}\")\n",
    "print(f\"‚úÖ RF  : AUC = {auc_rf:.4f}, Accuracy = {accuracy_score(y_valid_split, y_pred_rf):.4f}, F1 = {f1_score(y_valid_split, y_pred_rf):.4f}\")\n",
    "\n",
    "# --- 11. SHAP-–∞–Ω–∞–ª–∏–∑ (LightGBM sklearn API) ---\n",
    "explainer = shap.Explainer(model_lgb)\n",
    "shap_values = explainer(X_full_prep)\n",
    "\n",
    "X_prep_df = pd.DataFrame(X_full_prep, columns=num_features + cat_features)\n",
    "\n",
    "shap.summary_plot(shap_values, features=X_prep_df, plot_type='bar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
